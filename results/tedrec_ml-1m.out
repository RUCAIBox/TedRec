command line args [-d ml-1m] will not be used in RecBole
08 Feb 13:46    INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = dataset/ml-1m
checkpoint_dir = saved
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 300
train_batch_size = 2048
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}
repeatable = True
metrics = ['Recall', 'NDCG']
topk = [10, 20]
valid_metric = NDCG@10
valid_metric_bigger = True
eval_batch_size = 2048
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = None
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id_list', 'item_id']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = ['item_id_list']
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = None
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = ['train', 'valid', 'test']

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.SEQUENTIAL
n_layers = 2
n_heads = 2
hidden_size = 300
inner_size = 256
hidden_dropout_prob = 0.5
attn_dropout_prob = 0.5
hidden_act = gelu
layer_norm_eps = 1e-12
initializer_range = 0.02
loss_type = CE
plm_suffix = feat1CLS
plm_size = 768
adaptor_dropout_prob = 0.2
adaptor_layers = [768, 300]
temperature = 0.07
n_exps = 8
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.RANKING
single_spec = True
local_rank = 0
device = cuda
valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}


08 Feb 13:47    INFO  ml-1m
The number of users: 6041
Average actions of users: 164.49850993377484
The number of items: 3417
Average actions of items: 290.85802107728335
The number of inters: 993571
The sparsity of the dataset: 95.18667604362095%
Remain Fields: ['user_id', 'item_id_list', 'item_id', 'item_length']
08 Feb 13:47    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
08 Feb 13:47    INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'LS': 'valid_and_test'}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]
08 Feb 13:47    INFO  TedRec(
  (item_embedding): Embedding(3417, 300, padding_idx=0)
  (position_embedding): Embedding(50, 300)
  (trm_encoder): TransformerEncoder(
    (layer): ModuleList(
      (0-1): 2 x TransformerLayer(
        (multi_head_attention): MultiHeadAttention(
          (query): Linear(in_features=300, out_features=300, bias=True)
          (key): Linear(in_features=300, out_features=300, bias=True)
          (value): Linear(in_features=300, out_features=300, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=300, out_features=300, bias=True)
          (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=300, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=300, bias=True)
          (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (LayerNorm): LayerNorm((300,), eps=1e-12, elementwise_affine=True)
  (dropout): Dropout(p=0.5, inplace=False)
  (loss_fct): CrossEntropyLoss()
  (plm_embedding): Embedding(3417, 768, padding_idx=0)
  (item_gating): Linear(in_features=300, out_features=1, bias=True)
  (fusion_gating): Linear(in_features=300, out_features=1, bias=True)
  (moe_adaptor): MoEAdaptorLayer(
    (experts): ModuleList(
      (0-7): 8 x DTRLayer(
        (dropout): Dropout(p=0.2, inplace=False)
        (lin): Linear(in_features=768, out_features=300, bias=False)
      )
    )
  )
)
Trainable parameters: 4252702
08 Feb 13:49    INFO  epoch 0 training [time: 121.18s, train loss: 3031.9653]
08 Feb 13:49    INFO  epoch 0 evaluating [time: 0.41s, valid_score: 0.091300]
08 Feb 13:49    INFO  valid result: 
recall@10 : 0.1848    recall@20 : 0.3007    ndcg@10 : 0.0913    ndcg@20 : 0.1204
08 Feb 13:49    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 13:51    INFO  epoch 1 training [time: 121.52s, train loss: 2729.4560]
08 Feb 13:51    INFO  epoch 1 evaluating [time: 0.40s, valid_score: 0.117000]
08 Feb 13:51    INFO  valid result: 
recall@10 : 0.2248    recall@20 : 0.3425    ndcg@10 : 0.117    ndcg@20 : 0.1467
08 Feb 13:51    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 13:53    INFO  epoch 2 training [time: 121.49s, train loss: 2669.9798]
08 Feb 13:53    INFO  epoch 2 evaluating [time: 0.37s, valid_score: 0.126000]
08 Feb 13:53    INFO  valid result: 
recall@10 : 0.2384    recall@20 : 0.353    ndcg@10 : 0.126    ndcg@20 : 0.1549
08 Feb 13:53    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 13:55    INFO  epoch 3 training [time: 121.86s, train loss: 2637.9703]
08 Feb 13:55    INFO  epoch 3 evaluating [time: 0.39s, valid_score: 0.128400]
08 Feb 13:55    INFO  valid result: 
recall@10 : 0.2465    recall@20 : 0.3647    ndcg@10 : 0.1284    ndcg@20 : 0.1581
08 Feb 13:55    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 13:57    INFO  epoch 4 training [time: 120.81s, train loss: 2615.9347]
08 Feb 13:57    INFO  epoch 4 evaluating [time: 0.37s, valid_score: 0.129300]
08 Feb 13:57    INFO  valid result: 
recall@10 : 0.2492    recall@20 : 0.3707    ndcg@10 : 0.1293    ndcg@20 : 0.1599
08 Feb 13:57    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 13:59    INFO  epoch 5 training [time: 120.97s, train loss: 2599.4822]
08 Feb 13:59    INFO  epoch 5 evaluating [time: 0.39s, valid_score: 0.134700]
08 Feb 13:59    INFO  valid result: 
recall@10 : 0.2556    recall@20 : 0.3733    ndcg@10 : 0.1347    ndcg@20 : 0.1643
08 Feb 13:59    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:01    INFO  epoch 6 training [time: 121.73s, train loss: 2586.4890]
08 Feb 14:01    INFO  epoch 6 evaluating [time: 0.37s, valid_score: 0.135700]
08 Feb 14:01    INFO  valid result: 
recall@10 : 0.2579    recall@20 : 0.3725    ndcg@10 : 0.1357    ndcg@20 : 0.1645
08 Feb 14:01    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:03    INFO  epoch 7 training [time: 121.57s, train loss: 2576.7161]
08 Feb 14:03    INFO  epoch 7 evaluating [time: 0.36s, valid_score: 0.137600]
08 Feb 14:03    INFO  valid result: 
recall@10 : 0.257    recall@20 : 0.3803    ndcg@10 : 0.1376    ndcg@20 : 0.1687
08 Feb 14:03    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:05    INFO  epoch 8 training [time: 121.08s, train loss: 2567.1276]
08 Feb 14:05    INFO  epoch 8 evaluating [time: 0.49s, valid_score: 0.137400]
08 Feb 14:05    INFO  valid result: 
recall@10 : 0.2546    recall@20 : 0.3816    ndcg@10 : 0.1374    ndcg@20 : 0.1693
08 Feb 14:07    INFO  epoch 9 training [time: 122.04s, train loss: 2559.4534]
08 Feb 14:07    INFO  epoch 9 evaluating [time: 0.40s, valid_score: 0.138400]
08 Feb 14:07    INFO  valid result: 
recall@10 : 0.2583    recall@20 : 0.377    ndcg@10 : 0.1384    ndcg@20 : 0.1683
08 Feb 14:08    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:10    INFO  epoch 10 training [time: 121.11s, train loss: 2553.1078]
08 Feb 14:10    INFO  epoch 10 evaluating [time: 0.37s, valid_score: 0.138800]
08 Feb 14:10    INFO  valid result: 
recall@10 : 0.2598    recall@20 : 0.3818    ndcg@10 : 0.1388    ndcg@20 : 0.1696
08 Feb 14:10    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:12    INFO  epoch 11 training [time: 121.39s, train loss: 2547.1715]
08 Feb 14:12    INFO  epoch 11 evaluating [time: 0.37s, valid_score: 0.140000]
08 Feb 14:12    INFO  valid result: 
recall@10 : 0.2624    recall@20 : 0.3786    ndcg@10 : 0.14    ndcg@20 : 0.1694
08 Feb 14:12    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:14    INFO  epoch 12 training [time: 119.66s, train loss: 2542.5861]
08 Feb 14:14    INFO  epoch 12 evaluating [time: 0.35s, valid_score: 0.140600]
08 Feb 14:14    INFO  valid result: 
recall@10 : 0.2642    recall@20 : 0.3861    ndcg@10 : 0.1406    ndcg@20 : 0.1714
08 Feb 14:14    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:16    INFO  epoch 13 training [time: 120.12s, train loss: 2537.7226]
08 Feb 14:16    INFO  epoch 13 evaluating [time: 0.38s, valid_score: 0.141800]
08 Feb 14:16    INFO  valid result: 
recall@10 : 0.2659    recall@20 : 0.3884    ndcg@10 : 0.1418    ndcg@20 : 0.1726
08 Feb 14:16    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:18    INFO  epoch 14 training [time: 120.24s, train loss: 2533.5068]
08 Feb 14:18    INFO  epoch 14 evaluating [time: 0.34s, valid_score: 0.141600]
08 Feb 14:18    INFO  valid result: 
recall@10 : 0.2654    recall@20 : 0.3844    ndcg@10 : 0.1416    ndcg@20 : 0.1717
08 Feb 14:20    INFO  epoch 15 training [time: 119.59s, train loss: 2529.5417]
08 Feb 14:20    INFO  epoch 15 evaluating [time: 0.35s, valid_score: 0.140100]
08 Feb 14:20    INFO  valid result: 
recall@10 : 0.2631    recall@20 : 0.3839    ndcg@10 : 0.1401    ndcg@20 : 0.1707
08 Feb 14:22    INFO  epoch 16 training [time: 119.84s, train loss: 2525.4996]
08 Feb 14:22    INFO  epoch 16 evaluating [time: 0.36s, valid_score: 0.143800]
08 Feb 14:22    INFO  valid result: 
recall@10 : 0.2712    recall@20 : 0.3816    ndcg@10 : 0.1438    ndcg@20 : 0.1717
08 Feb 14:22    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:24    INFO  epoch 17 training [time: 119.96s, train loss: 2522.5226]
08 Feb 14:24    INFO  epoch 17 evaluating [time: 0.33s, valid_score: 0.138700]
08 Feb 14:24    INFO  valid result: 
recall@10 : 0.2603    recall@20 : 0.3848    ndcg@10 : 0.1387    ndcg@20 : 0.17
08 Feb 14:26    INFO  epoch 18 training [time: 118.53s, train loss: 2519.3840]
08 Feb 14:26    INFO  epoch 18 evaluating [time: 0.34s, valid_score: 0.140800]
08 Feb 14:26    INFO  valid result: 
recall@10 : 0.2656    recall@20 : 0.3836    ndcg@10 : 0.1408    ndcg@20 : 0.1706
08 Feb 14:28    INFO  epoch 19 training [time: 118.21s, train loss: 2516.7339]
08 Feb 14:28    INFO  epoch 19 evaluating [time: 0.35s, valid_score: 0.140100]
08 Feb 14:28    INFO  valid result: 
recall@10 : 0.2631    recall@20 : 0.3816    ndcg@10 : 0.1401    ndcg@20 : 0.1701
08 Feb 14:30    INFO  epoch 20 training [time: 118.35s, train loss: 2513.8348]
08 Feb 14:30    INFO  epoch 20 evaluating [time: 0.35s, valid_score: 0.143800]
08 Feb 14:30    INFO  valid result: 
recall@10 : 0.2664    recall@20 : 0.3821    ndcg@10 : 0.1438    ndcg@20 : 0.1731
08 Feb 14:30    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:32    INFO  epoch 21 training [time: 118.06s, train loss: 2510.6953]
08 Feb 14:32    INFO  epoch 21 evaluating [time: 0.33s, valid_score: 0.140800]
08 Feb 14:32    INFO  valid result: 
recall@10 : 0.2646    recall@20 : 0.3853    ndcg@10 : 0.1408    ndcg@20 : 0.1712
08 Feb 14:34    INFO  epoch 22 training [time: 118.36s, train loss: 2508.4701]
08 Feb 14:34    INFO  epoch 22 evaluating [time: 0.41s, valid_score: 0.143100]
08 Feb 14:34    INFO  valid result: 
recall@10 : 0.2671    recall@20 : 0.3834    ndcg@10 : 0.1431    ndcg@20 : 0.1725
08 Feb 14:36    INFO  epoch 23 training [time: 118.78s, train loss: 2506.1868]
08 Feb 14:36    INFO  epoch 23 evaluating [time: 0.27s, valid_score: 0.142100]
08 Feb 14:36    INFO  valid result: 
recall@10 : 0.2627    recall@20 : 0.3836    ndcg@10 : 0.1421    ndcg@20 : 0.1726
08 Feb 14:38    INFO  epoch 24 training [time: 118.48s, train loss: 2504.0009]
08 Feb 14:38    INFO  epoch 24 evaluating [time: 0.34s, valid_score: 0.144400]
08 Feb 14:38    INFO  valid result: 
recall@10 : 0.2695    recall@20 : 0.3786    ndcg@10 : 0.1444    ndcg@20 : 0.172
08 Feb 14:38    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:40    INFO  epoch 25 training [time: 118.87s, train loss: 2501.9407]
08 Feb 14:40    INFO  epoch 25 evaluating [time: 0.34s, valid_score: 0.144500]
08 Feb 14:40    INFO  valid result: 
recall@10 : 0.2697    recall@20 : 0.3879    ndcg@10 : 0.1445    ndcg@20 : 0.1743
08 Feb 14:40    INFO  Saving current: saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 14:41    INFO  epoch 26 training [time: 118.53s, train loss: 2499.9539]
08 Feb 14:42    INFO  epoch 26 evaluating [time: 0.35s, valid_score: 0.141600]
08 Feb 14:42    INFO  valid result: 
recall@10 : 0.2642    recall@20 : 0.3828    ndcg@10 : 0.1416    ndcg@20 : 0.1715
08 Feb 14:43    INFO  epoch 27 training [time: 118.03s, train loss: 2497.8314]
08 Feb 14:43    INFO  epoch 27 evaluating [time: 0.29s, valid_score: 0.142800]
08 Feb 14:43    INFO  valid result: 
recall@10 : 0.2662    recall@20 : 0.3826    ndcg@10 : 0.1428    ndcg@20 : 0.1722
08 Feb 14:45    INFO  epoch 28 training [time: 118.63s, train loss: 2496.5262]
08 Feb 14:45    INFO  epoch 28 evaluating [time: 0.34s, valid_score: 0.143600]
08 Feb 14:45    INFO  valid result: 
recall@10 : 0.2687    recall@20 : 0.3854    ndcg@10 : 0.1436    ndcg@20 : 0.1729
08 Feb 14:47    INFO  epoch 29 training [time: 118.19s, train loss: 2495.0252]
08 Feb 14:47    INFO  epoch 29 evaluating [time: 0.35s, valid_score: 0.142600]
08 Feb 14:47    INFO  valid result: 
recall@10 : 0.2674    recall@20 : 0.3864    ndcg@10 : 0.1426    ndcg@20 : 0.1726
08 Feb 14:49    INFO  epoch 30 training [time: 118.31s, train loss: 2493.1383]
08 Feb 14:49    INFO  epoch 30 evaluating [time: 0.35s, valid_score: 0.140700]
08 Feb 14:49    INFO  valid result: 
recall@10 : 0.2603    recall@20 : 0.3856    ndcg@10 : 0.1407    ndcg@20 : 0.1723
08 Feb 14:51    INFO  epoch 31 training [time: 118.36s, train loss: 2491.8519]
08 Feb 14:51    INFO  epoch 31 evaluating [time: 0.27s, valid_score: 0.141800]
08 Feb 14:51    INFO  valid result: 
recall@10 : 0.2637    recall@20 : 0.3816    ndcg@10 : 0.1418    ndcg@20 : 0.1716
08 Feb 14:53    INFO  epoch 32 training [time: 118.09s, train loss: 2490.0585]
08 Feb 14:53    INFO  epoch 32 evaluating [time: 0.34s, valid_score: 0.142300]
08 Feb 14:53    INFO  valid result: 
recall@10 : 0.2652    recall@20 : 0.3816    ndcg@10 : 0.1423    ndcg@20 : 0.1717
08 Feb 14:55    INFO  epoch 33 training [time: 118.14s, train loss: 2488.4718]
08 Feb 14:55    INFO  epoch 33 evaluating [time: 0.34s, valid_score: 0.143500]
08 Feb 14:55    INFO  valid result: 
recall@10 : 0.2667    recall@20 : 0.3863    ndcg@10 : 0.1435    ndcg@20 : 0.1738
08 Feb 14:57    INFO  epoch 34 training [time: 118.71s, train loss: 2486.9839]
08 Feb 14:57    INFO  epoch 34 evaluating [time: 0.34s, valid_score: 0.142400]
08 Feb 14:57    INFO  valid result: 
recall@10 : 0.2666    recall@20 : 0.3796    ndcg@10 : 0.1424    ndcg@20 : 0.1709
08 Feb 14:59    INFO  epoch 35 training [time: 118.42s, train loss: 2485.9322]
08 Feb 14:59    INFO  epoch 35 evaluating [time: 0.34s, valid_score: 0.142400]
08 Feb 14:59    INFO  valid result: 
recall@10 : 0.2677    recall@20 : 0.3801    ndcg@10 : 0.1424    ndcg@20 : 0.1707
08 Feb 15:01    INFO  epoch 36 training [time: 118.39s, train loss: 2484.8449]
08 Feb 15:01    INFO  epoch 36 evaluating [time: 0.40s, valid_score: 0.143600]
08 Feb 15:01    INFO  valid result: 
recall@10 : 0.2642    recall@20 : 0.3858    ndcg@10 : 0.1436    ndcg@20 : 0.1743
08 Feb 15:01    INFO  Finished training, best eval result in epoch 25
08 Feb 15:01    INFO  Loading model structure and parameters from saved/TedRec-Feb-08-2024_13-47-34.pth
08 Feb 15:01    INFO  best valid : OrderedDict([('recall@10', 0.2697), ('recall@20', 0.3879), ('ndcg@10', 0.1445), ('ndcg@20', 0.1743)])
08 Feb 15:01    INFO  test result: OrderedDict([('recall@10', 0.2623), ('recall@20', 0.3709), ('ndcg@10', 0.1445), ('ndcg@20', 0.1719)])
08 Feb 15:01    INFO  0.2623	0.3709	0.1445	0.1719
Namespace(d='ml-1m')
['props/TedRec.yaml', 'props/overall.yaml']
